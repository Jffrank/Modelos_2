{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con una capa escondida\n",
    "\n",
    "En este taller vamos a implementar una red neuronal con una sola capa escondida. Podremos ver la diferencia de este modelo con la regresión logística que implementamos en el taller anterior.\n",
    "\n",
    "**Tras este taller usted va a ser capaz de:**\n",
    "- Implementar una red neuronal de una capa escondida para un problema de clasificación binario\n",
    "- Usar unidades/neuronas con una función de activación no-lineal, como por ejemplo la tanh \n",
    "- Computar la función de pérdida de entropía cruzada \n",
    "- Implementar la propagación hacia delante y hacia atrás\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Paquetes ##\n",
    "\n",
    "Primero, importamos los paquetes que vamos a necesitar a lo largo de este taller. \n",
    "- [numpy](www.numpy.org) paquete básico para ciencias computacionales con Python.\n",
    "- [sklearn](http://scikit-learn.org/stable/) herramientas eficientes para el análisis y la minería de datos. \n",
    "- [matplotlib](http://matplotlib.org) librería para graficar en Python.\n",
    "- testCases tiene los ejemplos de prueba para evaluar la implementacion de las funciones\n",
    "- planar_utils provee distintas funciones que se van a usar durante el taller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de paquetes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from planar_utils0 import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1) # se establece una semilla para que los resultados sean iguales (necesario para la corrección del taller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Conjunto de datos ##\n",
    "\n",
    "Primero, carguemos el conjunto de datos sobre el que se va a trabajar. El siguiente código va a cargar un conjunto de datos en forma de flor, con dos clases en las variables `X` e `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice los datos mediante matplotlib. Los datos tienen puntos rojos (y=0) y azules (y=1). El objetivo es el de constuir un modelo que se ajuste a estos datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualice los datos:\n",
    "plt.scatter(X[0, :], X[1, :], c=Y[0,:], s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces se tiene una matriz X con los patrones (x1, x2), y un vector Y con las etiquetas (rojo:0, azul:1).\n",
    "\n",
    "Examinemos a continuación los datos.\n",
    "\n",
    "**Ejercicio**: Cuántos ejemplos de entrenamiento tenemos? Adicionalmente, cuáles son las dimensiones `shape` de `X` e `Y`? \n",
    "\n",
    "**Ayuda**: Recuerde cómo obtener la forma de un arreglo numpy [(ayuda)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 3 líneas de código)\n",
    "shape_X = \n",
    "shape_Y = \n",
    "m =           # tamaño del conjunto de entrenamiento\n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print ('Las dimensiones de X son: ' + str(shape_X))\n",
    "print ('Las dimensiones de Y son: ' + str(shape_Y))\n",
    "print ('Hay m = %d ejemplos de entrenamiento' % (m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "       \n",
    "<table style=\"width:40%\">\n",
    "  \n",
    "  <tr>\n",
    "    <td>**Dimensiones de X**</td>\n",
    "    <td> (2, 400) </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**Dimensiones de Y**</td>\n",
    "    <td>(1, 400) </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**m**</td>\n",
    "    <td> 400 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Regresión Logística\n",
    "\n",
    "Antes de contruir una red neuronal, primero estudiemos cómo la regresión logística se comporta con este problema. Se pueden utilizar las funciones de sklearn para hacerlo. Ejecute el siguiente código para entrenar un clasificador de regresión logística sobre el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrene el clasificador logístico\n",
    "clf = sklearn.linear_model.LogisticRegressionCV();\n",
    "Y2=Y.flatten()\n",
    "clf.fit(X.T, Y2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se puede graficar la frontera de decisión de estos modelos. Ejecute el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grafique la frontera de decisión para la regresión logística\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y2)\n",
    "plt.title(\"Regresión logística\")\n",
    "\n",
    "# Precisión\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('Precisión de la regresión logística: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(porcentaje de puntos correctamente etiquetados)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**Precisión**</td>\n",
    "    <td> 47% </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anotación**: como se esperaba, el conjunto de datos no es linealmente separable. Por esto, la regresión logística no logra un buen desempeño. Puede ser que la red neuronal logre un mejor desempeño. Vamos a ver! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Modelo de red neuronal\n",
    "\n",
    "La regresión logística no logró buenos resultados sobre el conjunto de datos. Ahora debe entrenar una red neuronal con una sola capa escondida.\n",
    "\n",
    "**Formulación matemática**:\n",
    "\n",
    "Para un ejemplo $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediccion} = \\begin{cases} 1 & \\mbox{si } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{en caso contrario (e.c.c.) } \\end{cases}\\tag{5}$$\n",
    "\n",
    "Dadas las predicciones sobre todos los ejemplos, tambien puede computar el coste $J$ como sigue: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
    "\n",
    "**Recuerde**: La metodología general para construir una red neuronal:\n",
    "    1. Definir una estructura de red neuronal ( # de unidades de input,  # de unidades escondidas, etc). \n",
    "    2. Inicialice los parámetros del modelo\n",
    "    3. Bucle:\n",
    "        - Implemente propagación hacia delante\n",
    "        - Compute la pérdida\n",
    "        - Implemente la propagación hacia atrás y obtenga los gradientes\n",
    "        - Actualice los parámetros (Descenso en la dirección del gradiente: GD)\n",
    "\n",
    "Se pueden construir funciones auxiliares para computar los pasos 1-3 y luego fusionarlas en una función (madre) llamada `nn_model()`. Una vez construida `nn_model()` y habiendo aprendido los parámetros adecuados, se pueden hacer predicciones sobre nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Definiendo la estructura de la red neuronal ####\n",
    "\n",
    "**Ejercicio**: Defina tres variables:\n",
    "    - n_x: tamaño de la capa de entrada\n",
    "    - n_h: tamaño de la capa oculta (en este ejemplo, fije su tamaño a 4) \n",
    "    - n_y: tamaño de la capa de salida\n",
    "\n",
    "**Ayuda**: Utilice las dimensiones de X e Y para encontrar n_x y n_y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: layer_sizes\n",
    "\n",
    "def layer_sizes(X, Y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X: conjunto de datos de entrada de dimensión (tamaño del input, número de ejemplos)\n",
    "    Y: etiquetas de tamaño (tamaño del output, número de ejemplos)\n",
    "    Output:\n",
    "    n_x: tamaño de la capa de entrada\n",
    "    n_h: tamaño de la capa escondida\n",
    "    n_y: tamaño de la capa de salida\n",
    "    \"\"\"\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 3 líneas de código)\n",
    "    n_x =    # tamaño de la capa de entrada\n",
    "    n_h = \n",
    "    n_y =    # tamaño de la acapa de salida\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess, Y_assess = layer_sizes_test_case()\n",
    "(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)\n",
    "print(\"El tamaño de la capa de entrada es: n_x = \" + str(n_x))\n",
    "print(\"El tamaño de la capa de escondida es: n_h = \" + str(n_h))\n",
    "print(\"El tamaño de la capa de salida es: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:  (esto es sólo para comnprobar que la función que has programado corre bien; en la implemenatción de la red utilizaremos otras dimensiones) \n",
    "\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**n_x**</td>\n",
    "    <td> 5 </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**n_h**</td>\n",
    "    <td> 4 </td> \n",
    "  </tr>\n",
    "  \n",
    "    <tr>\n",
    "    <td>**n_y**</td>\n",
    "    <td> 2 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Initialización de los parámetros del modelo ####\n",
    "\n",
    "**Ejercicio**: Implemente la función `initialize_parameters()`.\n",
    "\n",
    "**Instrucciones**:\n",
    "- Asegúrese de que las dimensiones de sus parámetros sean las correctas. Se puede referir al modelo de red neuronal de la figura anterior. \n",
    "- Inicialize los pesos con valores aleatorios. \n",
    "    - Use: `np.random.randn(a,b) * 0.01` para esta inicialización aleatoria de una matriz de dimensiones (a,b).\n",
    "- Inicialize los vectores de sesgo con ceros. \n",
    "    - Use: `np.zeros((a,b))` para la inicialización con ceros de la matriz de tamaño (a,b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    n_x: tamaño de la capa de entrada\n",
    "    n_h: tamaño de la capa escondida\n",
    "    n_y: tamaño de la capa de salida\n",
    "    Output:\n",
    "    params: diccionario python con los parámetros:\n",
    "                    W1: matriz de pesos con dimensiones (n_h, n_x)\n",
    "                    b1: matriz de sesgos con dimensiones (n_h, 1)\n",
    "                    W2: matriz de pesos con dimensiones (n_y, n_h)\n",
    "                    b2: matriz de sesgos con dimensiones (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2) # no cambie esta semilla para la replicabilidad de la simulación.\n",
    "    \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    W1 = \n",
    "    b1 = \n",
    "    W2 = \n",
    "    b2 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x, n_h, n_y = initialize_parameters_test_case()\n",
    "\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:90%\">\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.00416758 -0.00056267]\n",
    " [-0.02136196  0.01640271]\n",
    " [-0.01793436 -0.00841747]\n",
    " [ 0.00502881 -0.01245288]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-0.01057952 -0.00909008  0.00551454  0.02292208]]</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - El bucle ####\n",
    "\n",
    "**Pregunta**: Implemente `forward_propagation()`.\n",
    "\n",
    "**Instrucciones**:\n",
    "- Revise arriba la representación matemática de su clasificador.\n",
    "- Puede usar la función `sigmoid()` (se ha importado junto con el cuaderno).\n",
    "- Puede usar la función `np.tanh()` (es parte de la biblioteca numpy).\n",
    "- Los pasos que debe implementar son:\n",
    "    1. Recupere cada parámetro del diccionario \"parameters\" (que es la salida de `initialize_parameters()`), utilizando `parameters[\"..\"]`.\n",
    "    2. Implemente la propagación hacia delante. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ y $A^{[2]}$ (el vector de todas sus predicciones sobre todos los ejemplos del conjunto de entrenamiento).\n",
    "- Los valores necesarios para calcular la retro-propagación son guardados en \"`cache`\". La `cache` será proporcionada como entrada a la función de retro-propagación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    X: datos de entrada de tamaño (n_x, m)\n",
    "    parameters: diccionario python con los parameters (salida de la funcion de inicialización)\n",
    "    Output:\n",
    "    A2: la salida de la función sigmoide de la segunda activación\n",
    "    cache: un diccionario conteniendo \"Z1\", \"A1\", \"Z2\" y \"A2\"\n",
    "    \"\"\"\n",
    "    # Recupere cada parámetro del diccionario \"parameters\"\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    W1 = \n",
    "    b1 =  \n",
    "    W2 =  \n",
    "    b2 =  \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Implemente la propagación hacia delante para calcular A2 (probabilidades)\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    Z1 =  \n",
    "    A1 =  \n",
    "    Z2 =  \n",
    "    A2 =  \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess, parameters = forward_propagation_test_case()\n",
    "A2, cache = forward_propagation(X_assess, parameters)\n",
    "\n",
    "print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <td> 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya has calculado $A^{[2]}$ (en la variable Python \"`A2`\"), conteniendo los $a^{[2](i)}$ para cada ejemplo ($i$), puede computar la función de coste:\n",
    "\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
    "\n",
    "**Ejercicio**: Implemente `compute_cost()` para calcular el valor de la pérdida $J$.\n",
    "\n",
    "**Instrucciones**:\n",
    "- Hay muchas maneras de implementar la pérdida de entropía-cruzada. Por ejemplo, se puede implementar de la siguiente manera\n",
    "$- \\sum\\limits_{i=0}^{m}  y^{(i)}\\log(a^{[2](i)})$:\n",
    "```python\n",
    "logprobs = np.multiply(np.log(A2),Y)\n",
    "cost = - np.sum(logprobs)                # no hay necesidad de usar un bucle!\n",
    "```\n",
    "\n",
    "(puede usar tanto `np.multiply()` y luego `np.sum()`, como también `np.dot()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: compute_cost\n",
    "\n",
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Compute el coste de entropía cruzada de la ecuación (13)\n",
    "    Input:\n",
    "    A2: la salida de la función sigmoide para la segunda activación, de tamaño (1, numero de ejemplos)\n",
    "    Y: vector de etiquetas de tamaño (1, numero de ejemplos)\n",
    "    parametros: diccionario python con los parametros W1, b1, W2 and b2\n",
    "    Ouput:\n",
    "    cost: coste de entropía cruzada \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # numero de ejemplos\n",
    "\n",
    "    # Coste de entropía cruzada\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    logprobs = \n",
    "    cost = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    cost = np.squeeze(cost)     # se asegura que el coste sea de la dimension esperada, e.g. un [[99]] lo torna en 99 \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2, Y_assess, parameters = compute_cost_test_case()\n",
    "\n",
    "print(\"coste = \" + str(compute_cost(A2, Y_assess, parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>**coste**</td>\n",
    "    <td> 0.693058761... </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la cache computada en la propagacion hacia delante, puede implementar propagación hacia atrás.\n",
    "\n",
    "**Ejercicio**: Implemente la función `backward_propagation()`.\n",
    "\n",
    "**Instrucciones**:\n",
    "La retro-propagación suele ser la parte más difícil (y más matemática) del deep learning. Recordemos lo que es la retro-propagación. Se deben utilizar las seis ecuaciones siguientes, desde que se está implementando la versión vectorizada.  \n",
    "\n",
    "<!--\n",
    "comentar en bloque\n",
    "!-->\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
    "\n",
    "- Nótese que $*$ denota multiplicación por cada elemento.\n",
    "- La notación que se utiliza es común en código de deep learning:\n",
    "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
    "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
    "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
    "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
    "    \n",
    "\n",
    "\n",
    "- Ayuda:\n",
    "    - Para computar dZ1 se debe calcular primero $g^{[1]'}(Z^{[1]})$. COmo $g^{[1]}(.)$ es la función de activación tanh, si $a = g^{[1]}(z)$ entonces $g^{[1]'}(z) = 1-a^2$. Entonces puede calcular \n",
    "    $g^{[1]'}(Z^{[1]})$ utilizando `(1 - np.power(A1, 2))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: backward_propagation\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implemente Retro-propagacion.\n",
    "    Input:\n",
    "    parametros: diccionario python con los parameteros \n",
    "    cache: un diccionario con \"Z1\", \"A1\", \"Z2\" y \"A2\".\n",
    "    X: datos de entrada de tamaño (2, numero de ejemplos)\n",
    "    Y: vector de etiquetas de tamaño (1, numero de ejemplos)\n",
    "    Output:\n",
    "    grads: diccionario python con los gradientes de los diferentes parametros\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Recupere W1 y W2 del diccionario \"parameters\".\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ###(≈ 2 líneas de código)\n",
    "    W1 = \n",
    "    W2 =\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "        \n",
    "    # Recupere A1 y A2 del diccionario \"cache\".\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    A1 = \n",
    "    A2 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Retro-propagacion: calcule dW1, db1, dW2, db2. \n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 6 líneas de código)\n",
    "    dZ2 = \n",
    "    dW2 = \n",
    "    db2 = \n",
    "    dZ1 = \n",
    "    dW1 = \n",
    "    db1 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, cache, X_assess, Y_assess = backward_propagation_test_case()\n",
    "\n",
    "grads = backward_propagation(parameters, cache, X_assess, Y_assess)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>**dW1**</td>\n",
    "    <td> [[ 0.00301023 -0.00747267]\n",
    " [ 0.00257968 -0.00641288]\n",
    " [-0.00156892  0.003893  ]\n",
    " [-0.00652037  0.01618243]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**db1**</td>\n",
    "    <td>  [[ 0.00176201]\n",
    " [ 0.00150995]\n",
    " [-0.00091736]\n",
    " [-0.00381422]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**dW2**</td>\n",
    "    <td> [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**db2**</td>\n",
    "    <td> [[-0.16655712]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Implemente la regla de actualización. Use el método de Descenso del Gradiente (GD). Debe usar (dW1, db1, dW2, db2) para actualizar (W1, b1, W2, b2).\n",
    "\n",
    "**Regla general del GD**: $ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ donde $\\alpha$ es la tasa de aprendizaje y $\\theta$ representa un parámetro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    Actualice los parametros usando la regla de actualización del GD\n",
    "    Input:\n",
    "    parametros: diccionario python con los parametros \n",
    "    grads: diccionario python con los gradientes \n",
    "    Output:\n",
    "    parametros: diccionario python con los parametros actualizados \n",
    "    \"\"\"\n",
    "    # Recupere cada parametro del diccionario \"parameters\"\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    W1 = \n",
    "    b1 = \n",
    "    W2 = \n",
    "    b2 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Recupere cada gradiente del diccionario \"grads\"\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    dW1 = \n",
    "    db1 =\n",
    "    dW2 = \n",
    "    db2 =\n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Regla de actualización para cada parametro\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "    W1 = \n",
    "    b1 = \n",
    "    W2 = \n",
    "    b2 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.00643025  0.01936718]\n",
    " [-0.02410458  0.03978052]\n",
    " [-0.01653973 -0.02096177]\n",
    " [ 0.01046864 -0.05990141]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ -1.02420756e-06]\n",
    " [  1.27373948e-05]\n",
    " [  8.32996807e-07]\n",
    " [ -3.20136836e-06]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.00010457]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Integre las partes 4.1, 4.2 y 4.3 en nn_model() ####\n",
    "\n",
    "**Ejercicio**: Construya su modelo de red neuronal en `nn_model()`.\n",
    "\n",
    "**Instrucciones**: El modelo de la red debe usar las funciones previamente construidas en el orden correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: nn_model\n",
    "\n",
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    X: datos de entrada de tamaño (2, numero de ejemplos)\n",
    "    Y: vector de etiquetas de tamaño (1, numero de ejemplos)\n",
    "    n_h: tamaño de la capa escondida\n",
    "    num_iterations: numero de iteraciones del bucle del GD\n",
    "    print_cost: si \"True\", muestra el coste cada 1000 iteraciones\n",
    "    Output:\n",
    "    parameters: parametros aprendidos por el modelo. Pueden utilizarse para la predicción\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    # Inicialize los parámetros, luego recupere W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 5 líneas de código)\n",
    "    parameters =\n",
    "    W1 = \n",
    "    b1 = \n",
    "    W2 = \n",
    "    b2 = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    # Bucle (GD)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 4 líneas de código)\n",
    "        # Propagación hacia delante. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = \n",
    "        \n",
    "        # Función de coste. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = \n",
    " \n",
    "        # Retro-propagacion. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = \n",
    " \n",
    "        # Actualizacion de parametros por GD. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters =\n",
    "        \n",
    "        ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "        \n",
    "        # Muestre el coste cada 1000 iteraciones\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Coste tras la iteración %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_assess, Y_assess = nn_model_test_case()\n",
    "parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:90%\">\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        **coste tras la iteracion 1000**\n",
    "    </td>\n",
    "    <td> \n",
    "        0.000218\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>**W1**</td>\n",
    "    <td> [[-0.65848169  1.21866811]\n",
    " [-0.76204273  1.39377573]\n",
    " [ 0.5792005  -1.10397703]\n",
    " [ 0.76773391 -1.41477129]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**b1**</td>\n",
    "    <td> [[ 0.287592  ]\n",
    " [ 0.3511264 ]\n",
    " [-0.2431246 ]\n",
    " [-0.35772805]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[-2.45566237 -3.27042274  2.00784958  3.36773273]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>**b2**</td>\n",
    "    <td> [[ 0.20459656]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Predicciones\n",
    "\n",
    "**Ejercicio**: Construya su modelo mediante la funcion predict().\n",
    "Use propagacion hacia delante para predecir los resultados.\n",
    "\n",
    "**Recuerde**: predicciones = $y_{prediccion} = \\mathbb 1 \\text{{activacion > 0.5}} = \\begin{cases}\n",
    "      1 & \\text{if}\\ activacion > 0.5 \\\\\n",
    "      0 & \\text{$e.c.c.$}\n",
    "    \\end{cases}$  \n",
    "    \n",
    "Como un ejemplo, si quiere fijar las entradas de una matriz de X a 0 y 1 basados en un umbral, se puede hacer como: ```X_new = (X > umbral)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN A CALIFICAR: predict\n",
    "\n",
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Usando las estimaciones de los parámetros, se debe predecir una clase para cada ehemplo de X\n",
    "    Input:\n",
    "    parameters: diccionario python con los parametros \n",
    "    X: datos de entrada de tamaño (n_x, m)\n",
    "    Output:\n",
    "    predictions: vector de predicciones para el modelo (rojo: 0 / azul: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute las probabilidades usando propagacion hacia delante, y clasifica a 0/1 usando 0.5 como umbral.\n",
    "    ### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 2 líneas de código)\n",
    "    A2, cache = \n",
    "    predictions = \n",
    "    ### TERMINE EL CÓDIGO AQUÍ ###\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, X_assess = predict_test_case()\n",
    "\n",
    "predictions = predict(parameters, X_assess)\n",
    "print(\"Predicción media = \" + str(np.mean(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>**Predicción media**</td>\n",
    "    <td> 0.666666666667 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es momento de ejecutar el modelo y ver su desempeño sobre el conjunto de datos. Ejecute el siguiente código para probar el modelo con una sola capa escondida de $n_h$ neuronas/unidades escondidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construya un modelo con una capa escondida de dimensión $n_h=4$\n",
    "### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "parameters = \n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# Grafique la frontera de decisión\n",
    "plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y2)\n",
    "plt.title(\"Frontera de decisión para una capa escondida de tamaño  \" + str(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "      \n",
    "    <td>**Coste tras la iteración 9000**</td>\n",
    "    <td> 0.218571 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy\n",
    "predictions = predict(parameters, X)\n",
    "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**: \n",
    "\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**Accuracy**</td>\n",
    "    <td> 90% </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión ($Accuracy$) es alta comparada con los resultados de la regresión logística. El modelo ha aprendido los patrones de los datos (su forma en flor). Las redes neuronales pueden aprender fronteras de decisión en alto grado no-lineales, a diferencia de la regresión logística. \n",
    "\n",
    "Ahora, encuentre el mejor modelo al intentar distintos tamaños de la capa escondida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Optimize el tamaño de la capa escondida ###\n",
    "\n",
    "De manera discreta, mediante un conjunto de posibles tamaños para la capa escondida (numero de neuronas en la capa escondida): hidden_layer_sizes = [1, 2, .. , H], encuentre el valor que logre los mejores resultados. Podrá observar distintos comportamientos del modelo para distintos tamaños de la capa escondida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 32))\n",
    "\n",
    "### EMPIEZE EL CÓDIGO AQUÍ ### (≈ 1 línea de código)\n",
    "hidden_layer_sizes = \n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "for i, n_h in enumerate(hidden_layer_sizes):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.title('Tamaño de la capa escondida %d' % n_h)\n",
    "    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n",
    "    plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y2)\n",
    "    predictions = predict(parameters, X)\n",
    "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
    "    print (\"Accuracy para {} uniandes escondidas: {} %\".format(n_h, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación**:\n",
    "- Modelos más complejos (con más unidades escondidas) logran un mejor ajuste al conjunto de entrenamiento, hasta que eventualmente los modelos más grandes se sobreajustan a los datos. \n",
    "- EL mejor tamaño para la capa escondida para estar alrededor de $n_h = 5$. De esta manera, un valor de esta magnitud parece ajustarse a los datos de buena manera, controlando el posible sobreajuste. \n",
    "- Más adelante estudiaremos la regularización, permitiendo el uso d emodelos más complejos (por ejemplo con $n_h = 50$) cuidando de no cometer un sobreajuste muy alto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas sugeridas**:\n",
    "\n",
    "Puede explorar qué ocurre si.. \n",
    "- ..cambia la función de activación de tanh a una activación sigmoide o ReLU?\n",
    "- ..cambia la tasa de aprendizaje. \n",
    "\n",
    "Se consiguen mejores resultados? \n",
    "\n",
    "\n",
    "- Y qué pasa si cambiamos el conjunto de datos? (Ver el siguiente punto)\n",
    "\n",
    "Puede elegir un conjunto de datos diferente, y probar qué ocurre al cambiar la función de activación o la tasa de aprendizaje. Visualize los resultados del mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Desempeño sobre otros conjuntos de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede revisar o ejecutar de nuevo el modelo para (al menos uno de) los conjunto de datos a continuación. Recuerde presentar los resultados del mejor modelo con un gráfico de la frontera de decisión aprendida y su correspondiente medida de precisión ($accuracy$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()\n",
    "\n",
    "datasets = {\"noisy_circles\": noisy_circles,\n",
    "            \"noisy_moons\": noisy_moons,\n",
    "            \"blobs\": blobs,\n",
    "            \"gaussian_quantiles\": gaussian_quantiles}\n",
    "\n",
    "### EMPIEZE EL CÓDIGO AQUÍ ### (elija el conjunto de datos)\n",
    "dataset = \"\"\n",
    "### TERMINE EL CÓDIGO AQUÍ ###\n",
    "\n",
    "X, Y = datasets[dataset]\n",
    "X, Y = X.T, Y.reshape(1, Y.shape[0])\n",
    "\n",
    "# binariza los cúmulos o clusters (blobs)\n",
    "if dataset == \"blobs\":\n",
    "    Y = Y%2\n",
    "\n",
    "# Visualiza los datos\n",
    "plt.scatter(X[0, :], X[1, :], c=Y[0,:], s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**En este taller debe haber aprendido a:**\n",
    "- Construir una red neuronal completa con una capa escondida\n",
    "- Hacer buen uso de una unidad no-lineal \n",
    "- Implementar propagación hacia delante y hacia atrás, y entrenar una red neuronal\n",
    "- Ver el impacto de cambiar el tamaño de la capa escondida, junto con la comprensión del sobre-ajuste.\n",
    "\n",
    "Referencias:\n",
    "- http://scs.ryerson.ca/~aharley/neural-networks/\n",
    "- http://cs231n.github.io/neural-networks-case-study/"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "wRuwL",
   "launcher_item_id": "NI888"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
